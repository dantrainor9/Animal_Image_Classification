{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Animal_Image_Classification_part_1.ipynb",
      "provenance": [],
      "mount_file_id": "18EIpsSHUu7IROATuGSi2VPv_54BcblBF",
      "authorship_tag": "ABX9TyOoui5ht41bPwxBzEEOMYHW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dantrainor9/Animal_Image_Classification/blob/main/Animal_Image_Classification_part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN5DTW0bBw07",
        "outputId": "6be20625-0a5a-4a5a-ecbd-69c0d324ecd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.5.4)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import timm\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, sampler, random_split"
      ],
      "metadata": {
        "id": "M5JNNNi1Cl3F"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Personal Projects/Animal Image Classification/dataset'"
      ],
      "metadata": {
        "id": "68E4tPZZCrqF"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.transforms import RandomRotation"
      ],
      "metadata": {
        "id": "bDtYXiWTC6am"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_loaders(filename, batch_size, train = False):\n",
        "  if train:\n",
        "    my_transforms = transforms.Compose([\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomVerticalFlip(),\n",
        "          transforms.ColorJitter(brightness=0.3),\n",
        "          transforms.RandomRotation(30),\n",
        "          transforms.Resize(256),\n",
        "          transforms.CenterCrop(224),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
        "    ])\n",
        "    all_data = datasets.ImageFolder(filename,transform=my_transforms)\n",
        "    train_len = int(len(all_data) * 0.7)\n",
        "    val_len = int((len(all_data) - train_len)/2)\n",
        "    test_len = int(len(all_data) - train_len-val_len)\n",
        "    train_data, val_data, test_data = random_split(all_data, [train_len, val_len, test_len])\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    return(train_loader, train_len, all_data)\n",
        "#generating DataLoader for train data\n",
        "\n",
        "  else:\n",
        "    my_transforms = transforms.Compose([\n",
        "          transforms.Resize(256),\n",
        "          transforms.CenterCrop(224),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
        "    ])\n",
        "    all_data = datasets.ImageFolder(filename, transform=my_transforms)\n",
        "    train_len = int(len(all_data)*0.7)\n",
        "    val_len = int((len(all_data)-train_len)/2)\n",
        "    test_len = int(len(all_data)-train_len-val_len)\n",
        "    train_data, val_data, test_data = random_split(all_data, [train_len,val_len,test_len])\n",
        "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    return(val_loader, val_len, test_loader, test_len)\n",
        "#generating DataLoader for test and validation data"
      ],
      "metadata": {
        "id": "lZnuRtao3emk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_classes(filename):\n",
        "  all_data = datasets.ImageFolder(filename)\n",
        "  return all_data.classes"
      ],
      "metadata": {
        "id": "83wpc5PTiXdC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instnatiating data loaders\n",
        "(train_loader, train_len, all_data) = get_data_loaders(path, 64, train=True)\n",
        "(val_loader, val_len, test_loader, test_len) = get_data_loaders(path, 64, train=False)\n",
        "classes = get_classes(path)"
      ],
      "metadata": {
        "id": "fJ8O5Llhio8q"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders = {'train':train_loader,\n",
        "               'val':val_loader}\n",
        "dataset_sizes = {'train_len':train_len,\n",
        "                 'val_len':val_len}"
      ],
      "metadata": {
        "id": "WcGZgm2yRT16"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_loader))\n",
        "print(len(val_loader))\n",
        "print(len(test_loader))\n",
        "print(train_len,test_len,val_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEflfms6XHmI",
        "outputId": "ebb66e07-057a-4d7d-a195-03fa8dd3d1d5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69\n",
            "15\n",
            "15\n",
            "4389 941 940\n"
          ]
        }
      ]
    }
  ]
}