{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Animal_Image_Classification_part_1.ipynb",
      "provenance": [],
      "mount_file_id": "18EIpsSHUu7IROATuGSi2VPv_54BcblBF",
      "authorship_tag": "ABX9TyOwK8WzArHQdiK+R8Ox8PV1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dantrainor9/Animal_Image_Classification/blob/main/Animal_Image_Classification_part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN5DTW0bBw07",
        "outputId": "57752c4b-cf06-4901-c9f2-58ce5efa6f92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-0.5.4-py3-none-any.whl (431 kB)\n",
            "\u001b[?25l\r\u001b[K     |▊                               | 10 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 20 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 30 kB 18.1 MB/s eta 0:00:01\r\u001b[K     |███                             | 40 kB 13.2 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 51 kB 8.0 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 61 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 71 kB 8.9 MB/s eta 0:00:01\r\u001b[K     |██████                          | 81 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 92 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 102 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 112 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 122 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 133 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 143 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 153 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 163 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 174 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 184 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 194 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 204 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 215 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 225 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 235 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 245 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 256 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 266 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 276 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 286 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 296 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 307 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 317 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 327 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 337 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 348 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 358 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 368 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 378 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 389 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 399 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 409 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 419 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 430 kB 8.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 431 kB 8.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.5.4\n"
          ]
        }
      ],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import timm\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, sampler, random_split"
      ],
      "metadata": {
        "id": "M5JNNNi1Cl3F"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Personal Projects/Animal Image Classification/dataset'"
      ],
      "metadata": {
        "id": "68E4tPZZCrqF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms.transforms import RandomRotation"
      ],
      "metadata": {
        "id": "bDtYXiWTC6am"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_loaders(filename, batch_size, train = False):\n",
        "  if train:\n",
        "    my_transforms = transforms.Compose([\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomVerticalFlip(),\n",
        "          transforms.ColorJitter(brightness=0.3),\n",
        "          transforms.RandomRotation(30),\n",
        "          transforms.Resize(256),\n",
        "          transforms.CenterCrop(224),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
        "    ])\n",
        "    all_data = datasets.ImageFolder(filename,transform=my_transforms)\n",
        "    train_len = int(len(all_data) * 0.7)\n",
        "    val_len = int((len(all_data) - train_len)/2)\n",
        "    test_len = int(len(all_data) - train_len-val_len)\n",
        "    train_data, val_data, test_data = random_split(all_data, [train_len, val_len, test_len])\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    return(train_loader, train_len, all_data)\n",
        "#generating DataLoader for train data\n",
        "\n",
        "  else:\n",
        "    my_transforms = transforms.Compose([\n",
        "          transforms.Resize(256),\n",
        "          transforms.CenterCrop(224),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
        "    ])\n",
        "    all_data = datasets.ImageFolder(filename, transform=my_transforms)\n",
        "    train_len = int(len(all_data)*0.7)\n",
        "    val_len = int((len(all_data)-train_len)/2)\n",
        "    test_len = int(len(all_data)-train_len-val_len)\n",
        "    train_data, val_data, test_data = random_split(all_data, [train_len,val_len,test_len])\n",
        "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    return(val_loader, val_len, test_loader, test_len)\n",
        "#generating DataLoader for test and validation data"
      ],
      "metadata": {
        "id": "lZnuRtao3emk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_classes(filename):\n",
        "  all_data = datasets.ImageFolder(filename)\n",
        "  return all_data.classes"
      ],
      "metadata": {
        "id": "83wpc5PTiXdC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instnatiating data loaders\n",
        "(train_loader, train_len, all_data) = get_data_loaders(path, 64, train=True)\n",
        "(val_loader, val_len, test_loader, test_len) = get_data_loaders(path, 64, train=False)\n",
        "classes = get_classes(path)"
      ],
      "metadata": {
        "id": "fJ8O5Llhio8q"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders = {'train':train_loader,\n",
        "               'val':val_loader}\n",
        "dataset_sizes = {'train_len':train_len,\n",
        "                 'val_len':val_len}"
      ],
      "metadata": {
        "id": "WcGZgm2yRT16"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_loader))\n",
        "print(len(val_loader))\n",
        "print(len(test_loader))\n",
        "print(train_len,test_len,val_len)\n",
        "#visualizing split sizes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEflfms6XHmI",
        "outputId": "2bccd501-134e-4fb4-c637-81bc77ee6d08"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69\n",
            "15\n",
            "15\n",
            "4389 941 940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AnimalClassifier(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(AnimalClassifier, self).__init__()\n",
        "    self.conv1 = torch.nn.Conv2d(3, 10, 5)\n",
        "    self.conv2 = torch.nn.Conv2d(10, 45, 3)\n",
        "    self.fc1 = torch.nn.Linear(45*10*10, 500)\n",
        "    self.fc2 = torch.nn.Linear(120,84)\n",
        "    self.fc3 = torch.nn.Linear(84,151)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
        "    x = F.max_pood2d(F.relu(self.conv2(x)), 2)\n",
        "    x = x.view(-1, self.num_flat_features(x))\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "  def num_flat_features(x):\n",
        "    size = x.size()[1:]\n",
        "    num_features=1\n",
        "    for s in size:\n",
        "        num_features *= s\n",
        "    return num_features"
      ],
      "metadata": {
        "id": "8yxV97-vkqDG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "dummy_out = torch.rand(10, 151)\n",
        "dumm_label = torch.tensor([1,6,8,3,9,4,2,5,7,4])"
      ],
      "metadata": {
        "id": "4XmQy_sPo6WR"
      },
      "execution_count": 12,
      "outputs": []
    }
  ]
}