{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Animal_Image_Classification_part_1.ipynb",
      "provenance": [],
      "mount_file_id": "18EIpsSHUu7IROATuGSi2VPv_54BcblBF",
      "authorship_tag": "ABX9TyPbfaDsUKc3q2oE4gE75oE4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dantrainor9/Animal_Image_Classification/blob/main/Animal_Image_Classification_part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN5DTW0bBw07",
        "outputId": "ca22a468-e8ce-4be5-b649-e449b32bf56d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: timm in /usr/local/lib/python3.7/dist-packages (0.5.4)\n",
            "Requirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from timm) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from timm) (0.11.1+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->timm) (3.10.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (1.21.5)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->timm) (7.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install timm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import timm\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import DataLoader, sampler, random_split"
      ],
      "metadata": {
        "id": "M5JNNNi1Cl3F"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/Personal Projects/Animal Image Classification/dataset'"
      ],
      "metadata": {
        "id": "68E4tPZZCrqF"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_data_loaders(filename, batch_size, train = False):\n",
        "  if train:\n",
        "    my_transforms = transforms.Compose([\n",
        "          transforms.RandomHorizontalFlip(),\n",
        "          transforms.RandomVerticalFlip(),\n",
        "          transforms.ColorJitter(brightness=0.3),\n",
        "          transforms.RandomRotation(30),\n",
        "          transforms.Resize(256),\n",
        "          transforms.CenterCrop(224),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
        "    ])\n",
        "    all_data = datasets.ImageFolder(filename,transform=my_transforms)\n",
        "    train_len = int(len(all_data) * 0.7)\n",
        "    val_len = int((len(all_data) - train_len)/2)\n",
        "    test_len = int(len(all_data) - train_len-val_len)\n",
        "    train_data, val_data, test_data = random_split(all_data, [train_len, val_len, test_len])\n",
        "    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    return(train_loader, train_len, all_data)\n",
        "#generating DataLoader for train data\n",
        "\n",
        "  else:\n",
        "    my_transforms = transforms.Compose([\n",
        "          transforms.Resize(256),\n",
        "          transforms.CenterCrop(224),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
        "    ])\n",
        "    all_data = datasets.ImageFolder(filename, transform=my_transforms)\n",
        "    train_len = int(len(all_data)*0.7)\n",
        "    val_len = int((len(all_data)-train_len)/2)\n",
        "    test_len = int(len(all_data)-train_len-val_len)\n",
        "    train_data, val_data, test_data = random_split(all_data, [train_len,val_len,test_len])\n",
        "    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    return(val_loader, val_len, test_loader, test_len)\n",
        "#generating DataLoader for test and validation data"
      ],
      "metadata": {
        "id": "lZnuRtao3emk"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_classes(filename):\n",
        "  all_data = datasets.ImageFolder(filename)\n",
        "  return all_data.classes"
      ],
      "metadata": {
        "id": "83wpc5PTiXdC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instnatiating data loaders\n",
        "(train_loader, train_len, all_data) = get_data_loaders(path, 64, train=True)\n",
        "(val_loader, val_len, test_loader, test_len) = get_data_loaders(path, 64, train=False)\n",
        "classes = get_classes(path)"
      ],
      "metadata": {
        "id": "fJ8O5Llhio8q"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataloaders = {'train':train_loader,\n",
        "               'val':val_loader}\n",
        "dataset_sizes = {'train_len':train_len,\n",
        "                 'val_len':val_len}"
      ],
      "metadata": {
        "id": "WcGZgm2yRT16"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_loader))\n",
        "print(len(val_loader))\n",
        "print(len(test_loader))\n",
        "print(train_len,test_len,val_len)\n",
        "#visualizing split sizes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEflfms6XHmI",
        "outputId": "aa85eb39-6873-49da-f51f-c975fc488a80"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "69\n",
            "15\n",
            "15\n",
            "4389 941 940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AnimalClassifier(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(AnimalClassifier, self).__init__()\n",
        "    self.conv1 = torch.nn.Conv2d(3, 10, 5)\n",
        "    self.conv2 = torch.nn.Conv2d(10, 45, 3)\n",
        "    self.fc1 = torch.nn.Linear(45*10*10, 500)\n",
        "    self.fc2 = torch.nn.Linear(120,84)\n",
        "    self.fc3 = torch.nn.Linear(84,151)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = F.max_pool2d(F.relu(self.conv1(x)), (2,2))\n",
        "    x = F.max_pood2d(F.relu(self.conv2(x)), 2)\n",
        "    x = x.view(-1, self.num_flat_features(x))\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = self.fc3(x)\n",
        "    return x\n",
        "\n",
        "  def num_flat_features(x):\n",
        "    size = x.size()[1:]\n",
        "    num_features=1\n",
        "    for s in size:\n",
        "        num_features *= s\n",
        "    return num_features\n",
        "\n",
        "model = AnimalClassifier()"
      ],
      "metadata": {
        "id": "8yxV97-vkqDG"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "dummy_out = torch.rand(10, 151)\n",
        "dummy_label = torch.tensor([1,6,8,3,9,4,2,5,7,4])"
      ],
      "metadata": {
        "id": "4XmQy_sPo6WR"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}